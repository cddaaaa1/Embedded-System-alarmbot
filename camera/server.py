import requests
import cv2
import mediapipe as mp
import numpy as np
import sys
import time

# -------------------------------
# 1. é…ç½®éƒ¨åˆ†
# -------------------------------
RASPBERRY_PI_IP = "http://172.20.10.7:5001"
ESP32_IP = "http://172.20.10.8"

HFOV = 62.2  # æ°´å¹³æ–¹å‘ FOV
VFOV = 48.8  # å‚ç›´æ–¹å‘ FOV

SEARCH_STEP_YAW = 15   # æœç´¢æ­¥é•¿
SEARCH_STEP_PITCH = 5  # æœç´¢æ­¥é•¿
SEARCH_DELAY = 0.5  # æœç´¢é—´éš”

CENTER_TOLERANCE = 10  # åç§»å°äº 8Â° æ—¶è®¤ä¸ºäººè„¸å·²å±…ä¸­

current_yaw = 0
current_pitch = 0
search_direction = 1  

mp_face_detection = mp.solutions.face_detection
face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)

# -------------------------------
# 2. å‘é€æŒ‡ä»¤
# -------------------------------
def request_capture():
    """ è¯·æ±‚æ ‘è“æ´¾æ‹ç…§ """
    response = requests.get(f"{RASPBERRY_PI_IP}/capture", stream=True)
    if response.status_code == 200:
        with open("received.jpg", "wb") as file:
            file.write(response.content)
        return "received.jpg"
    return None

def send_servo_angles(yaw_offset, pitch_offset):
    """ å‘é€è§’åº¦è°ƒæ•´åˆ° ESP32 """
    requests.post(f"{ESP32_IP}/update_angles", json={"yaw": yaw_offset, "pitch": pitch_offset})

# -------------------------------
# 3. å¤„ç†å›¾åƒ & è¿½è¸ªäººè„¸
# -------------------------------
def process_image(image_path):
    """ å¤„ç†å›¾åƒï¼Œè°ƒæ•´èˆµæœºè§’åº¦ï¼Œå¹¶æ˜¾ç¤ºæ‘„åƒå¤´ç”»é¢ """
    global current_yaw, current_pitch, search_direction

    frame = cv2.imread(image_path)
    if frame is None:
        return None

    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = face_detection.process(rgb_frame)

    if results.detections:
        # -------- æ£€æµ‹åˆ°äººè„¸ --------
        for detection in results.detections:
            bboxC = detection.location_data.relative_bounding_box
            x, y, w, h = int(bboxC.xmin * frame.shape[1]), int(bboxC.ymin * frame.shape[0]), \
                         int(bboxC.width * frame.shape[1]), int(bboxC.height * frame.shape[0])
            face_center_x, face_center_y = x + w // 2, y + h // 2
            CENTER_X, CENTER_Y = frame.shape[1] // 2, frame.shape[0] // 2

            # è®¡ç®—è§’åº¦åç§»é‡
            yaw_offset = (face_center_x - CENTER_X) / frame.shape[1] * HFOV * 0.5
            pitch_offset = (face_center_y - CENTER_Y) / frame.shape[0] * VFOV * 0.5

            print(f"âœ… Face Detected! Yaw Offset: {yaw_offset:.2f}Â°, Pitch Offset: {pitch_offset:.2f}Â°")

            # ç»˜åˆ¶æ£€æµ‹æ¡†å’Œè§’åº¦ä¿¡æ¯
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
            cv2.putText(frame, f"Yaw: {yaw_offset:.2f}Â°, Pitch: {pitch_offset:.2f}Â°",
                        (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

            # æ˜¾ç¤ºæ‘„åƒå¤´ç”»é¢
            cv2.imshow("Face Tracking", frame)
            cv2.waitKey(1)  # æ›´æ–°çª—å£ï¼Œä¸é˜»å¡ç¨‹åº

            # **å¦‚æœäººè„¸è¶³å¤Ÿå±…ä¸­ï¼Œåœæ­¢æœç´¢**
            if abs(yaw_offset) < CENTER_TOLERANCE and abs(pitch_offset) < CENTER_TOLERANCE:
                print("ğŸ¯ Face is centered! Stopping tracking.")
                return {"yaw": 0, "pitch": 0}  # è®©èˆµæœºä¸å†è°ƒæ•´

            # å¦åˆ™ç»§ç»­è°ƒæ•´
            send_servo_angles(yaw_offset, pitch_offset)
            return {"yaw": yaw_offset, "pitch": pitch_offset}  

    else:
        # -------- æœªæ£€æµ‹åˆ°äººè„¸ï¼Œç»§ç»­æœç´¢æ¨¡å¼ --------
        print("ğŸ” No face detected. Searching...")

        # æœç´¢æ¨¡å¼å¯è§†åŒ–
        cv2.putText(frame, "NO FACE DETECTED", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 
                    1, (0, 0, 255), 2)
        cv2.imshow("Face Tracking", frame)
        cv2.waitKey(1)

        # è°ƒæ•´èˆµæœºæœç´¢
        current_yaw += search_direction * SEARCH_STEP_YAW
        if abs(current_yaw) > 90:
            search_direction *= -1
            current_pitch += SEARCH_STEP_PITCH  
            if abs(current_pitch) > 45:
                search_direction *= -1  
                current_pitch += SEARCH_STEP_PITCH

        send_servo_angles(search_direction * SEARCH_STEP_YAW, search_direction * SEARCH_STEP_PITCH)
        return None

# -------------------------------
# 4. ä¸»æµç¨‹
# -------------------------------
if __name__ == '__main__':
    while True:
        cmd = input("\nPress 's' to start tracking, 'q' to quit: ").strip().lower()
        if cmd == "s":
            print("ğŸ” Starting face search...")
            while True:
                image_path = request_capture()
                if image_path:
                    result = process_image(image_path)
                    if result and result["yaw"] == 0 and result["pitch"] == 0:  
                        print("âœ… Face is perfectly centered. Stopping search.")
                        break  
                time.sleep(SEARCH_DELAY)  
        elif cmd == "q":
            print("Exiting...")
            cv2.destroyAllWindows()  # å…³é—­æ‰€æœ‰çª—å£
            break